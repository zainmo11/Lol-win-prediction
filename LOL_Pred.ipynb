{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#include <iostream>\n","#include <vector>\n","#include <cstdlib>\n","#include <cmath>\n","#include <ctime>\n","#include <algorithm>\n","\n","// Define the Neuron class\n","class Neuron {\n","public:\n","    Neuron() = default;\n","    Neuron(int n_weights) {\n","        initWeights(n_weights);\n","        m_nWeights = n_weights;\n","        m_activation = 0;\n","        m_output = 0;\n","        m_delta = 0;\n","    }\n","\n","    ~Neuron() {}\n","\n","    void activate(const std::vector<float>& inputs) {\n","        m_activation = m_weights[m_nWeights - 1]; // Bias weight\n","        for (size_t i = 0; i < m_nWeights - 1; ++i) {\n","            m_activation += m_weights[i] * inputs[i];\n","        }\n","    }\n","\n","    void transfer() {\n","        m_output = 1.0f / (1.0f + std::exp(-m_activation));\n","    }\n","\n","    float transfer_derivative() const {\n","        return m_output * (1.0f - m_output);\n","    }\n","\n","    std::vector<float>& get_weights() { return m_weights; }\n","    float get_output() const { return m_output; }\n","    float get_activation() const { return m_activation; }\n","    float get_delta() const { return m_delta; }\n","    void set_delta(float delta) { m_delta = delta; }\n","\n","private:\n","    size_t m_nWeights;\n","    std::vector<float> m_weights;\n","    float m_activation;\n","    float m_output;\n","    float m_delta;\n","\n","    void initWeights(int n_weights) {\n","        m_weights.resize(n_weights);\n","        for (int w = 0; w < n_weights; ++w) {\n","            m_weights[w] = static_cast<float>(std::rand()) / static_cast<float>(RAND_MAX);\n","        }\n","    }\n","};\n","\n","// Define the Layer class\n","class Layer {\n","public:\n","    Layer() = default;\n","    Layer(int n_neurons, int n_weights) {\n","        initNeurons(n_neurons, n_weights);\n","    }\n","\n","    ~Layer() {}\n","\n","    std::vector<Neuron>& get_neurons() { return m_neurons; }\n","\n","private:\n","    void initNeurons(int n_neurons, int n_weights) {\n","        m_neurons.resize(n_neurons, Neuron(n_weights));\n","    }\n","\n","    std::vector<Neuron> m_neurons;\n","};\n","\n","// Define the Network class\n","class Network {\n","public:\n","    Network() {\n","        std::srand(static_cast<unsigned int>(std::time(nullptr)));\n","        m_nLayers = 0;\n","    }\n","\n","    ~Network() {}\n","\n","    void initialize_network(int n_inputs, int n_hidden, int n_outputs) {\n","        add_layer(n_hidden, n_inputs + 1); // +1 for bias weight\n","        add_layer(n_hidden, n_hidden + 1); // +1 for bias weight\n","        add_layer(n_outputs, n_hidden + 1); // +1 for bias weight\n","    }\n","\n","    void add_layer(int n_neurons, int n_weights) {\n","        m_layers.emplace_back(n_neurons, n_weights);\n","        m_nLayers++;\n","    }\n","\n","    std::vector<float> forward_propagate(const std::vector<float>& inputs) {\n","        std::vector<float> new_inputs = inputs;\n","        for (const auto& layer : m_layers) {\n","            std::vector<float> layer_outputs;\n","            for (const auto& neuron : layer.get_neurons()) {\n","                neuron.activate(new_inputs);\n","                neuron.transfer();\n","                layer_outputs.push_back(neuron.get_output());\n","            }\n","            new_inputs = layer_outputs;\n","        }\n","        return new_inputs;\n","    }\n","\n","    void backward_propagate_error(const std::vector<float>& expected) {\n","        for (size_t i = m_nLayers; i-- > 0;) {\n","            auto& layer_neurons = m_layers[i].get_neurons();\n","            for (size_t n = 0; n < layer_neurons.size(); ++n) {\n","                float error = 0.0;\n","                if (i == m_nLayers - 1) {\n","                    error = expected[n] - layer_neurons[n].get_output();\n","                } else {\n","                    for (const auto& next_neuron : m_layers[i + 1].get_neurons()) {\n","                        error += (next_neuron.get_weights()[n] * next_neuron.get_delta());\n","                    }\n","                }\n","                layer_neurons[n].set_delta(error * layer_neurons[n].transfer_derivative());\n","            }\n","        }\n","    }\n","\n","    void update_weights(const std::vector<float>& inputs, float l_rate) {\n","        std::vector<float> prev_layer_outputs = inputs;\n","        for (size_t i = 0; i < m_nLayers; ++i) {\n","            std::vector<float> layer_inputs;\n","            if (i != 0) {\n","                for (const auto& neuron : m_layers[i - 1].get_neurons()) {\n","                    layer_inputs.push_back(neuron.get_output());\n","                }\n","            } else {\n","                layer_inputs = inputs;\n","            }\n","\n","            auto& layer_neurons = m_layers[i].get_neurons();\n","            for (size_t n = 0; n < layer_neurons.size(); ++n) {\n","                auto& weights = layer_neurons[n].get_weights();\n","                for (size_t j = 0; j < layer_inputs.size(); ++j) {\n","                    weights[j] += l_rate * layer_neurons[n].get_delta() * layer_inputs[j];\n","                }\n","                weights.back() += l_rate * layer_neurons[n].get_delta(); // Update bias weight\n","            }\n","        }\n","    }\n","\n","    void train(const std::vector<std::vector<float>>& training_data, float l_rate, size_t n_epoch, size_t n_outputs) {\n","        for (size_t e = 0; e < n_epoch; ++e) {\n","            float sum_error = 0;\n","            for (const auto& row : training_data) {\n","                std::vector<float> outputs = forward_propagate(row);\n","                std::vector<float> expected(n_outputs, 0.0f);\n","                expected[static_cast<int>(row.back())] = 1.0f;\n","                for (size_t x = 0; x < n_outputs; ++x) {\n","                    sum_error += std::pow((expected[x] - outputs[x]), 2);\n","                }\n","                backward_propagate_error(expected);\n","                update_weights(row, l_rate);\n","            }\n","            std::cout << \"[>] epoch=\" << e << \", l_rate=\" << l_rate << \", error=\" << sum_error << std::endl;\n","        }\n","    }\n","\n","    int predict(const std::vector<float>& input) {\n","        std::vector<float> outputs = forward_propagate(input);\n","        return std::max_element(outputs.begin(), outputs.end()) - outputs.begin();\n","    }\n","\n","    void display_human() const {\n","        std::cout << \"[Network] (Layers: \" << m_nLayers << \")\" << std::endl;\n","        std::cout << \"{\" << std::endl;\n","        for (size_t l = 0; l < m_layers.size(); ++l) {\n","            const auto& layer = m_layers[l];\n","            std::cout << \"\\t(Layer \" << l << \"): {\";\n","            for (size_t i = 0; i < layer.get_neurons().size(); ++i) {\n","                const auto& neuron = layer.get_neurons()[i];\n","                std::cout << \"<(Neuron \" << i << \"): [ weights={\";\n","                const auto& weights = neuron.get_weights();\n","                for (size_t w = 0; w < weights.size(); ++w) {\n","                    std::cout << weights[w];\n","                    if (w < weights.size() - 1) {\n","                        std::cout << \", \";\n","                    }\n","                }\n","                std::cout << \"}, output=\" << neuron.get_output()\n","                          << \", activation=\" << neuron.get_activation()\n","                          << \", delta=\" << neuron.get_delta()\n","                          << \"]>\";\n","                if (i < layer.get_neurons().size() - 1) {\n","                    std::cout << \", \";\n","                }\n","            }\n","            std::cout << \"}\";\n","            if (l < m_layers.size() - 1) {\n","                std::cout << \", \";\n","            }\n","            std::cout << std::endl;\n","        }\n","        std::cout << \"}\" << std::endl;\n","    }\n","\n","private:\n","    size_t m_nLayers;\n","    std::vector<Layer> m_layers;\n","};\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","std::vector<float> evaluate_network(std::vector<std::vector<float>> dataset, int n_folds, float l_rate, int n_epoch, int n_hidden) {\n","\n","\t/* Split dataset into k folds */\n","\n","\tstd::vector<std::vector<std::vector<float>>> dataset_splits;\n","\t// initialize prng\n","\tstd::srand(static_cast<unsigned int>(std::time(nullptr)));\n","\n","\tstd::vector<float> scores;\n","\n","\tsize_t fold_size = static_cast<unsigned int>(dataset.size() / n_folds);\n","\tfor (int f = 0; f < n_folds; f++)\n","\t{\n","\t\tstd::vector<std::vector<float>> fold;\n","\t\twhile (fold.size() < fold_size) {\n","\t\t\tint n = rand() % dataset.size(); // get a random index\n","\n","\t\t\t// add the chosen element to the fold and remove it from the dataset\n","\t\t\tstd::swap(dataset[n], dataset.back());\n","\t\t\tfold.push_back(dataset.back());\n","\t\t\tdataset.pop_back();\n","\t\t}\n","\n","\t\tdataset_splits.push_back(fold);\n","\t}\n","\n","\t/* Iterate over folds */\n","\t// choose one as test and the rest as training sets\n","\tfor (size_t i = 0; i < dataset_splits.size(); i++)\n","\t{\n","\t\tstd::vector<std::vector<std::vector<float>>> train_sets = dataset_splits;\n","\t\tstd::swap(train_sets[i], train_sets.back());\n","\t\tstd::vector<std::vector<float>> test_set = train_sets.back();\n","\t\ttrain_sets.pop_back();\n","\n","\t\t// merge the multiple train_sets into one train set\n","\t\tstd::vector<std::vector<float>> train_set;\n","\t\tfor (auto &s: train_sets)\n","\t\t{\n","\t\t\tfor (auto& row : s) {\n","\t\t\t\ttrain_set.push_back(row);\n","\t\t\t}\n","\t\t}\n","\n","\t\t// store the expected results\n","\t\tstd::vector<int> expected;\n","\t\tfor (auto& row: test_set)\n","\t\t{\n","\t\t\texpected.push_back(static_cast<int>(row.back()));\n","\t\t\t// just ensure that the actual result is not saved in the test data\n","\t\t\trow.back() = 42;\n","\t\t}\n","\n","\t\tstd::vector<int> predicted;\n","\n","\t\tstd::set<float> results;\n","\t\tfor (const auto& r : train_set) {\n","\t\t\tresults.insert(r.back());\n","\t\t}\n","\t\tint n_outputs = results.size();\n","\t\tint n_inputs = train_set[0].size() - 1;\n","\n","\t\t/* Backpropagation with stochastic gradient descent */\n","\t\tNetwork* network = new Network();\n","\t\tnetwork->initialize_network(n_inputs, n_hidden, n_outputs);\n","\t\tnetwork->train(train_set, l_rate, n_epoch, n_outputs);\n","\n","\t\tfor (const auto& row: test_set)\n","\t\t{\n","\t\t\tpredicted.push_back(network->predict(row));\n","\t\t}\n","\n","\t\tscores.push_back(accuracy_metric(expected, predicted));\n","\t}\n","\n","\treturn scores;\n","}\n","\n","/*\n","*\n","*/\n","float accuracy_metric(std::vector<int> expect, std::vector<int> predict) {\n","\tint correct = 0;\n","\n","\tfor (size_t i = 0; i < predict.size(); i++)\n","\t{\n","\t\tif (predict[i] == expect[i]) {\n","\t\t\tcorrect++;\n","\t\t}\n","\t}\n","\treturn static_cast<float>(correct * 100.0f / predict.size());\n","}\n","\n","/*\n","* Load comma separated values from file and normalize the values\n","*/\n","std::vector<std::vector<float>> load_csv_data(std::string filename) {\n","\tconst std::regex comma(\",\");\n","\n","\tstd::ifstream csv_file(filename);\n","\n","\tstd::vector<std::vector<float>> data;\n","\n","\tstd::string line;\n","\n","\tstd::vector<float> mins;\n","\tstd::vector<float> maxs;\n","\tbool first = true;\n","\n","\twhile (csv_file && std::getline(csv_file, line)) {\n","\t\t// split line by commas\n","\t\tstd::vector<std::string> srow{ std::sregex_token_iterator(line.begin(), line.end(), comma, -1), std::sregex_token_iterator() };\n","\t\t// create float vector\n","\t\tstd::vector<float> row(srow.size());\n","\t\t// transform the strings to floats\n","\t\tstd::transform(srow.begin(), srow.end(), row.begin(), [](std::string const& val) {return std::stof(val); });\n","\n","\t\t// keep track of the min and max value for each column for subsequent normalization\n","\t\tif (first) {\n","\t\t\tmins = row;\n","\t\t\tmaxs = row;\n","\t\t\tfirst = false;\n","\t\t}\n","\t\telse {\n","\t\t\tfor (size_t t=0; t < row.size(); t++)\n","\t\t\t{\n","\t\t\t\tif (row[t] > maxs[t]) {\n","\t\t\t\t\tmaxs[t] = row[t];\n","\t\t\t\t}\n","\t\t\t\telse if (row[t] < mins[t]) {\n","\t\t\t\t\tmins[t] = row[t];\n","\t\t\t\t}\n","\t\t\t}\n","\t\t}\n","\n","\t\tdata.push_back(row);\n","\t}\n","\n","\t// normalize values\n","\tfor (auto& vec : data) {\n","\t\t// ignore the last column (the output)\n","\t\tfor (size_t i = 0; i < vec.size()-1; i++)\n","\t\t{\n","\t\t\tvec[i] = (vec[i] - mins[i]) / (maxs[i] - mins[i]);\n","\t\t}\n","\t}\n","\n","\treturn data;\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["int main() {\n","\t\n","\tstd::vector<std::vector<float>> csv_data;\n","\tcsv_data = load_csv_data(\"../data/data.csv\");\n","\n","\t/*\n","\t* Normalize the last column (turning the outputs into values starting from 0 for the one-hot encoding in the end)\n","\t*/\n","\tstd::map<int, int> lookup = {};\n","\tint index = 0;\n","\tfor (auto& vec : csv_data) {\n","\t\tstd::pair<std::map<int, int>::iterator, bool> ret;\n","\t\t// insert unique values\n","\t\tret = lookup.insert(std::pair<int, int>(static_cast<int>(vec.back()),index));\n","\t\t// update the vector with the new index\n","\t\tvec.back() = static_cast<float>(ret.first->second);\n","\t\t// if an actual new value was found, increase the index\n","\t\tif (ret.second) {\n","\t\t\tindex++;\n","\t\t}\n","\t}\n","\n","\tint n_folds = 5;\t\t// how many folds you want to create from the given dataset\n","\tfloat l_rate = 0.3f;\t// how much of an impact shall an error have on a weight\n","\tint n_epoch = 500;\t\t// how many times should weights be updated\n","\tint n_hidden = 5;\t\t// how many neurons you want in the first layer\n","\n","\t// test the implemented neural network\n","\tstd::vector<float> scores = evaluate_network(csv_data, n_folds, l_rate, n_epoch, n_hidden);\n","\n","\t// calculate the mean average of the scores across each cross validation\n","\tfloat mean = std::accumulate(scores.begin(), scores.end(), decltype(scores)::value_type(0)) / static_cast<float>(scores.size());\n","\n","\tstd::cout << \"Mean accuracy: \" << mean << std::endl;\n","\n","\treturn 0;\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["main()"]}],"metadata":{"kernelspec":{"display_name":"C++17","language":"C++17","name":"xcpp17"},"language_info":{"codemirror_mode":"text/x-c++src","file_extension":".cpp","mimetype":"text/x-c++src","name":"c++","version":"17"}},"nbformat":4,"nbformat_minor":5}
